{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab13_exercises.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Principal Component Analysis"
      ],
      "metadata": {
        "id": "0TRW769UviGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, we'll see in practice how to use Principal Component Analysis (PCA) to reduce the dimensionality of a dataset, and how to interpret the principal components. To this end, we'll use the \"Wisconsin Breast Cancer dataset\", which contains diverse characteristics of cancerous cell nuclei, and whether the patient's tumor is malignant (M) or benign (B). In the second part of the lab, we'll see how PCA can be used to compress an image. "
      ],
      "metadata": {
        "id": "6Wv_p-C5vtEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the necessary libraries**"
      ],
      "metadata": {
        "id": "SJrpIZNhw_wK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhVzgj_HOHit"
      },
      "outputs": [],
      "source": [
        "import sklearn \n",
        "import pandas as pd \n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Read the dataset, drop the columns 'id' and 'Unnamed : 32', and check whether there are missing values. If any, drop the entire corresponding row.**"
      ],
      "metadata": {
        "id": "ud0SDrc2xDn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Select X as all columns in the dataframe, at the exception of the target variable 'diagnosis', and y as the variable diagnosis. Center the matrix X column-wise.**"
      ],
      "metadata": {
        "id": "5JlJfmxfxiSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Compute the total variance of the variable X.**"
      ],
      "metadata": {
        "id": "X-jy8912yE8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Apply PCA to the dataset X by computing all principal components. Make sure you can access to the principal components, the variance explained by each component and the ratio of variance explained by each component.**"
      ],
      "metadata": {
        "id": "ipo98LY5yS7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Create a barplot of the proportion of total variance explained by the first 5 components. What do you observe ?**\n",
        "\n",
        "**Generate also a barplot of the cumulative ratio of the total variance explained by the first 5 components.**\n",
        "\n",
        "**Also, what is the proportion of the total variance explained by all the components ?**"
      ],
      "metadata": {
        "id": "gyfp2zIeze8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Generate a biplot of the component's scores in the space spanned by the first two components. Color the points depending on their target label ('M' or 'B'). Do you notice anything ?**"
      ],
      "metadata": {
        "id": "VaE6VhCf1MPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7) Generate a table of the loadings for the first two principal components, i.e. a pandas Dataframe which columns are the principal components, and which rows are the loadings for each variable. Set the Dataframe's indices to be the original variable names. How do you interpret it ?**"
      ],
      "metadata": {
        "id": "N2sQPSRi5Q5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8) Use the function below to generate a loading plot. How do you interpret it ?**"
      ],
      "metadata": {
        "id": "-AnpD_8V74lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def myplot(score,coeff,labels=None):\n",
        "    fig, ax = plt.subplots()\n",
        "    xs = score[:,0]\n",
        "    ys = score[:,1]\n",
        "    n = coeff.shape[0]\n",
        "    scalex = 1.0/(xs.max() - xs.min())\n",
        "    scaley = 1.0/(ys.max() - ys.min())\n",
        "    ax.scatter(xs*scalex, ys*scaley, c = y)\n",
        "    for i in range(n):\n",
        "        ax.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n",
        "        if labels is None:\n",
        "            ax.text(coeff[i,0]* 1.15 , coeff[i,1] * 1.15 , \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
        "        else:\n",
        "            ax.text(coeff[i,0]* 1.15 , coeff[i,1] * 1.15 , labels[i], color = 'g', ha = 'center', va = 'center')\n",
        "    plt.xlim(-0.5,1.1)\n",
        "    plt.ylim(-1,1.1)\n",
        "    ax.set_xlabel(\"PC{}\".format(1))\n",
        "    ax.set_ylabel(\"PC{}\".format(2))\n",
        "    fig.set_size_inches(18.5, 10.5)\n"
      ],
      "metadata": {
        "id": "Z8FYAJLcxdrk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9) Split X (the centered data) and y into a training and a test set following a 80/20 partition. Fit a logistic regression model to the training data using all original variables, and evaluate its accuracy on the test set. Redo the same, but create a pipeline that adds a PCA pre-processing step to the data X. Fit the model on only the two first principal components. Is the difference in accuracy significant between the two approaches ?**"
      ],
      "metadata": {
        "id": "fmFXxtqrCJo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10) We'll now see how PCA can be employed to compress an image. First, load the 'doggo.jpeg' picture using the library matplotlib.**"
      ],
      "metadata": {
        "id": "MoD52zwBDd2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11) Split the image into its red, green and blue channels (using the method cv2.split()). Then, on each channel, apply a PCA transformation with 1 component. For each channel, also compute the inverse PCA transform (using the pca.inverse_transform() method).**\n",
        "\n",
        "**Stack the three inverted transforms (one for each channel) back together to form the compressed imgage, and display the image. Try by increasing the number of principal components until you reach a satisfactory quality.***"
      ],
      "metadata": {
        "id": "rnevCJjcEiw1"
      }
    }
  ]
}